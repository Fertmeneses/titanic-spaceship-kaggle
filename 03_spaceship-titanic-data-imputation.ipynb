{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7d4b3aa-1f7d-4c3c-93a4-4568b513bbbd",
   "metadata": {},
   "source": [
    "<a id=\"Title\"></a>\n",
    "# <span style=\"color:teal;font-weight:bold;\">Spaceship Titanic ü©π Data imputation</span>\n",
    "\n",
    "This notebook is the third part of my <span style=\"font-weight:bold;color:green\">Spaceship Titanic series</span>:\n",
    "\n",
    "1. <a href=\"https://www.kaggle.com/code/fertmeneses/spaceship-titanic-getting-familiar\">Spaceship Titanic üèÅ Getting familiar</a>.\n",
    "2. <a href=\"https://www.kaggle.com/code/fertmeneses/spaceship-titanic-feature-engineering\">Spaceship Titanic üí° Feature engineering.</a>\n",
    "3. <span style=\"font-weight:bold\">Spaceship Titanic ü©π Data imputation.</span> [This notebook]\n",
    "4. Spaceship Titanic üñ•Ô∏è Model optimization. (Coming soon)\n",
    "5. Spaceship Titanic üî≠ Integrated analysis. (Coming soon)\n",
    "\n",
    "In the <span style=\"color:orangered;font-weight:bold;\">first episode</span>, I studied the Leaderboard (LB) and tried simple Machine Learning models with the original dataset, getting a <span style=\"color:orangered;font-weight:bold;\">submission score of 0.79635</span>. \n",
    "\n",
    "From that experience, I learned that **$\\approx$75% of the submissions in the LB are below a 0.80 score, while only $\\approx$5% are above 0.81**.\n",
    "\n",
    "In the <span style=\"color:orange;font-weight:bold;\">second episode</span>, I performed feature engineering on the original dataset (without any data correction), getting a <span style=\"color:orange;font-weight:bold;\">submission score of 0.80336</span>.\n",
    "\n",
    "<div style=\"color:white;\n",
    "    display:fill;\n",
    "    border-radius:15px;\n",
    "    margin-left: 100px;\n",
    "    margin-right: 100px;\n",
    "    background-color:lightblue;\n",
    "    font-size:105%;\n",
    "    font-family:Verdana;\n",
    "    letter-spacing:0.5px\">\n",
    "\n",
    "<p style=\"padding: 20px;color:black;text-align:center;\">\n",
    "In this <span style=\"color:green;font-weight:bold;\">notebook</span>, I use my previously engineered features and focus on <span style=\"font-weight:bold;\">data imputation</span> employing my own Machine Learning methods, getting a <span style=\"color:green;font-weight:bold;\">submission score of X</span>.\n",
    "\n",
    "</p>\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "In the future notebooks, I'll optimize the Machine Learning model and finally make an integrated analysis based on my results and a deep study of other kagglers' contributions.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92087346-b763-486d-9ec7-73c774358411",
   "metadata": {},
   "source": [
    "# <font color='teal'>Outline</font> <a class=\"anchor\"  id=\"Outline\"></a>\n",
    "\n",
    "[**Load data and preprocess**](#Load_data_and_preprocess)\n",
    "\n",
    "  - [Load original data](#Load_original_data)\n",
    "\n",
    "  - [Basic feature engineering](#Basic_feature_engineering)\n",
    "\n",
    "[**Manual data correction**](#Manual_data_correction)\n",
    "\n",
    "  - [Feature_X](#Manual_data_correction_Feature_X)\n",
    "\n",
    "[**ML data imputation**](#ML_data_imputation)\n",
    "\n",
    "  - [Method description](#Method_description)\n",
    "\n",
    "  - [Data selection](#Data_selection)\n",
    "\n",
    "  - [Model tests](#Model_tests)\n",
    "\n",
    "  - [Data imputation](#Data_imputation)\n",
    "\n",
    "    - [Feature_X](#Data_imputation_Feature_X)\n",
    "  \n",
    "[**Feature engineering**](#Feature_engineering)\n",
    "\n",
    "  - [Engineer features](#Engineer_features)\n",
    "   \n",
    "  - [Correlations](#Correlations)\n",
    "   \n",
    "  - [Combined features](#Feature_engineering_combined)\n",
    "   \n",
    "[**Submission results**](#Submission_results)\n",
    "\n",
    "  - [Try models](#Try_models)\n",
    "    \n",
    "  - [Analyze results](#Analyze_results)\n",
    "  \n",
    "[**Conclusions**](#Conclusions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324337ff-eb9c-4e10-af5a-24be73de43ea",
   "metadata": {},
   "source": [
    "<a id=\"Load_data_and_preprocess\"></a>\n",
    "# <span style=\"color:teal;font-weight:bold;\">Load data and preprocess</span>\n",
    "\n",
    "In this section, I load the original data and do basic feature engineering, in which I only extract information from single variables or change names. Other feature engineering processes that involve relating two or more features will come later, once I've corrected the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "482f75e3-3a65-4038-92c8-cf08094ccc25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook last run (end-to-end): 2024-09-28 17:07:29.208300\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(f\"Notebook last run (end-to-end): {datetime.datetime.now()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7915230d-b4f6-415e-8e6a-5ce2ed8f16b8",
   "metadata": {},
   "source": [
    "<a id=\"Load_original_data\"></a>\n",
    "## <span style=\"color:teal;font-weight:bold;\">Load original data</span>\n",
    "\n",
    "In the following lines, I load the original datasets and get this information:\n",
    "\n",
    "- Example for 10 random rows in training dataset.\n",
    "\n",
    "- Number of rows in both datasets.\n",
    "\n",
    "- Features' names and data types.\n",
    "\n",
    "- Number of missing values in both datasets, per feature and per row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e5cf416-cac1-45f4-be71-e957ad7212d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>1539_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A/17/S</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>32.0</td>\n",
       "      <td>False</td>\n",
       "      <td>54.0</td>\n",
       "      <td>3782.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Alyadum Barmant</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>0232_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>G/36/S</td>\n",
       "      <td>PSO J318.5-22</td>\n",
       "      <td>27.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Nica Bakerrison</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7866</th>\n",
       "      <td>8392_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1610/S</td>\n",
       "      <td>PSO J318.5-22</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>86.0</td>\n",
       "      <td>669.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Therly Brightez</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7622</th>\n",
       "      <td>8141_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>G/1310/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>38.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Stenny Belley</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4108</th>\n",
       "      <td>4387_01</td>\n",
       "      <td>Mars</td>\n",
       "      <td>False</td>\n",
       "      <td>F/902/P</td>\n",
       "      <td>PSO J318.5-22</td>\n",
       "      <td>32.0</td>\n",
       "      <td>False</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Apix Wala</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4363</th>\n",
       "      <td>4645_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/184/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>48.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9633.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Aton Bacistion</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>0379_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>G/63/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>31.0</td>\n",
       "      <td>False</td>\n",
       "      <td>198.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>591.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>Brita Moodson</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5966</th>\n",
       "      <td>6324_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>E/420/S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>False</td>\n",
       "      <td>19.0</td>\n",
       "      <td>509.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>Lesley Hinetthews</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>0699_01</td>\n",
       "      <td>Mars</td>\n",
       "      <td>True</td>\n",
       "      <td>F/126/S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Roswal Sha</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6506</th>\n",
       "      <td>6865_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>D/208/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.0</td>\n",
       "      <td>2878.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4232.0</td>\n",
       "      <td>3798.0</td>\n",
       "      <td>Thabih Peducting</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId HomePlanet CryoSleep     Cabin    Destination   Age    VIP  \\\n",
       "1454     1539_01     Europa       NaN    A/17/S    55 Cancri e  32.0  False   \n",
       "218      0232_01      Earth      True    G/36/S  PSO J318.5-22  27.0  False   \n",
       "7866     8392_01      Earth     False  F/1610/S  PSO J318.5-22  24.0  False   \n",
       "7622     8141_01      Earth      True  G/1310/S    TRAPPIST-1e  38.0  False   \n",
       "4108     4387_01       Mars     False   F/902/P  PSO J318.5-22  32.0  False   \n",
       "4363     4645_01     Europa     False   B/184/S    TRAPPIST-1e  48.0  False   \n",
       "343      0379_01      Earth     False    G/63/P    TRAPPIST-1e  31.0  False   \n",
       "5966     6324_01      Earth     False   E/420/S            NaN  31.0  False   \n",
       "669      0699_01       Mars      True   F/126/S            NaN  18.0  False   \n",
       "6506     6865_01     Europa     False   D/208/S    TRAPPIST-1e  27.0    NaN   \n",
       "\n",
       "      RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
       "1454         54.0     3782.0           0.0    21.0     5.0    Alyadum Barmant   \n",
       "218           0.0        NaN           0.0     0.0     0.0    Nica Bakerrison   \n",
       "7866         86.0      669.0           1.0     0.0     0.0    Therly Brightez   \n",
       "7622          0.0        0.0           0.0     0.0     0.0      Stenny Belley   \n",
       "4108        192.0        0.0         441.0    18.0     0.0          Apix Wala   \n",
       "4363          0.0     9633.0           0.0     1.0     2.0     Aton Bacistion   \n",
       "343         198.0        0.0         591.0     0.0   164.0      Brita Moodson   \n",
       "5966         19.0      509.0           0.0     0.0   177.0  Lesley Hinetthews   \n",
       "669           0.0        0.0           0.0     0.0     0.0         Roswal Sha   \n",
       "6506         69.0     2878.0           0.0  4232.0  3798.0   Thabih Peducting   \n",
       "\n",
       "      Transported  \n",
       "1454         True  \n",
       "218         False  \n",
       "7866        False  \n",
       "7622         True  \n",
       "4108        False  \n",
       "4363         True  \n",
       "343          True  \n",
       "5966        False  \n",
       "669          True  \n",
       "6506        False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of rows in train/test datasets:\n",
      "\n",
      "8693 / 4277\n",
      "\n",
      "Features: names and data types:\n",
      "\n",
      "PassengerId      object\n",
      "HomePlanet       object\n",
      "CryoSleep        object\n",
      "Cabin            object\n",
      "Destination      object\n",
      "Age             float64\n",
      "VIP              object\n",
      "RoomService     float64\n",
      "FoodCourt       float64\n",
      "ShoppingMall    float64\n",
      "Spa             float64\n",
      "VRDeck          float64\n",
      "Name             object\n",
      "Transported        bool\n",
      "dtype: object\n",
      "\n",
      "Missing values in train/test datasets:\n",
      "\n",
      "PassengerId:             \u001b[32m0 (0.0%)\u001b[0m / \u001b[32m0 (0.0%)\u001b[0m\n",
      "HomePlanet:           \u001b[31m201 (2.3%)\u001b[0m / \u001b[31m87 (2.0%)\u001b[0m\n",
      "CryoSleep:            \u001b[31m217 (2.5%)\u001b[0m / \u001b[31m93 (2.2%)\u001b[0m\n",
      "Cabin:               \u001b[31m199 (2.3%)\u001b[0m / \u001b[31m100 (2.3%)\u001b[0m\n",
      "Destination:          \u001b[31m182 (2.1%)\u001b[0m / \u001b[31m92 (2.2%)\u001b[0m\n",
      "Age:                  \u001b[31m179 (2.1%)\u001b[0m / \u001b[31m91 (2.1%)\u001b[0m\n",
      "VIP:                  \u001b[31m203 (2.3%)\u001b[0m / \u001b[31m93 (2.2%)\u001b[0m\n",
      "RoomService:          \u001b[31m181 (2.1%)\u001b[0m / \u001b[31m82 (1.9%)\u001b[0m\n",
      "FoodCourt:           \u001b[31m183 (2.1%)\u001b[0m / \u001b[31m106 (2.5%)\u001b[0m\n",
      "ShoppingMall:         \u001b[31m208 (2.4%)\u001b[0m / \u001b[31m98 (2.3%)\u001b[0m\n",
      "Spa:                 \u001b[31m183 (2.1%)\u001b[0m / \u001b[31m101 (2.4%)\u001b[0m\n",
      "VRDeck:               \u001b[31m188 (2.2%)\u001b[0m / \u001b[31m80 (1.9%)\u001b[0m\n",
      "Name:                 \u001b[31m200 (2.3%)\u001b[0m / \u001b[31m94 (2.2%)\u001b[0m\n",
      "Number of rows with 0 missing values: 6606/3281\n",
      "Number of rows with 1 missing values: 1867/879\n",
      "Number of rows with 2 missing values: 203/113\n",
      "Number of rows with 3 missing values: 17/4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from termcolor import colored\n",
    "\n",
    "# Load original datasets:\n",
    "train_df = pd.read_csv('kaggle/input/spaceship-titanic/train.csv') # Training dataset\n",
    "test_df = pd.read_csv('kaggle/input/spaceship-titanic/test.csv') # Testing dataset\n",
    "# Keep the passengerID features separately:\n",
    "train_ID = train_df['PassengerId']\n",
    "test_ID = test_df['PassengerId']\n",
    "# Display a 10 random examples:\n",
    "np.random.seed(1) # Ensure reproducitibility\n",
    "samples = np.random.choice(range(len(train_df)), 10, replace=False)\n",
    "display(train_df.iloc[samples]) # Examples\n",
    "# Print global information:\n",
    "print('\\nNumber of rows in train/test datasets:\\n')\n",
    "print(len(train_df),'/',len(test_df))\n",
    "print('\\nFeatures: names and data types:\\n')\n",
    "print(train_df.dtypes)\n",
    "# Print number of missing values per feature:\n",
    "print('\\nMissing values in train/test datasets:\\n')\n",
    "for col in test_df.columns:\n",
    "    # Count missing values and obtain percentages:\n",
    "    N_train = train_df[col].isna().sum() \n",
    "    N_test = test_df[col].isna().sum()\n",
    "    p_train = N_train/len(train_df)*100 # [%]\n",
    "    p_test = N_test/len(test_df)*100 # [%]\n",
    "    # Print results:\n",
    "    color_train = 'red' if N_train else 'green'\n",
    "    color_test = 'red' if N_test else 'green'\n",
    "    rmargin = 60-len(col)\n",
    "    text_train = colored(f'{N_train} ({p_train:.1f}%)', color_train)\n",
    "    text_test = colored(f'{N_test} ({p_test:.1f}%)', color_test)\n",
    "    print(f'{col}:',f'{text_train} / {text_test}'.rjust(rmargin))\n",
    "# Count missing values in each row:\n",
    "N_nan_train = train_df.apply(lambda x: x.isna().sum(), axis=1)\n",
    "N_nan_test = test_df.apply(lambda x: x.isna().sum(), axis=1) \n",
    "# Print number of rows with N missing values:\n",
    "for n in set(N_nan_train).union(set(N_nan_test)):\n",
    "    print(f'Number of rows with {n} missing values: {sum(N_nan_train==n)}/{sum(N_nan_test==n)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4942b2ca-9a94-41bf-a758-6b8eb4ad9b14",
   "metadata": {},
   "source": [
    "For more comments about the features, please visit <a href=\"https://www.kaggle.com/code/fertmeneses/spaceship-titanic-feature-engineering\">Spaceship Titanic üí° Feature engineering.</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db3f715-6231-4bd6-8d98-fb2681996195",
   "metadata": {},
   "source": [
    "<a id=\"Basic_feature_engineering\"></a>\n",
    "## <span style=\"color:teal;font-weight:bold;\">Basic feature engineering</span>\n",
    "\n",
    "Except for the **PassengerID** feature, there are around 2% missing values in both the training and testing datasets. In order to correct them, I'll make some fair assumptions and deductions using the original information. \n",
    "\n",
    "Then, **in this Basic feature engineering process I won't generate new features that involve two or more features, because that would multiply the missing values**. Instead, I will just extract information from the original features or do simple changes such as changing the feature name.\n",
    "\n",
    "You can check my previous notebook <a href=\"https://www.kaggle.com/code/fertmeneses/spaceship-titanic-feature-engineering\">Spaceship Titanic üí° Feature engineering.</a> for details about the engineering of single features. In the following, I just apply that code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fdaa7353-a30a-4d28-83c0-3079de030e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First generate the corrected datasets:\n",
    "train_df_SF = train_df.copy()\n",
    "test_df_SF = test_df.copy()\n",
    "\n",
    "# # # \"PassengerId\": new features \"IDgroup\" and \"GroupMembers\" # # #\n",
    "\n",
    "train_df_SF['IDgroup'] = train_df['PassengerId'].apply(\n",
    "    lambda x: int(x.split('_')[0]))\n",
    "test_df_SF['IDgroup'] = test_df['PassengerId'].apply(\n",
    "    lambda x: int(x.split('_')[0]))\n",
    "# Identify ocurrences for every unique value in IDgroup:\n",
    "ocurrences = pd.concat([train_df_SF['IDgroup'], test_df_SF['IDgroup']]).value_counts().to_dict()\n",
    "for dataset in [train_df_SF,test_df_SF]:\n",
    "    dataset['GroupMembers'] = dataset['IDgroup'].apply(lambda x: ocurrences[x])\n",
    "# Drop unnecessary feature:\n",
    "train_df_SF = train_df_SF.drop('PassengerId',axis=1)\n",
    "test_df_SF = test_df_SF.drop('PassengerId',axis=1)\n",
    "\n",
    "# # # \"CryoSleep\": make boolean/numeric # # #\n",
    "\n",
    "for dataset in [train_df_SF,test_df_SF]:\n",
    "    dataset['CryoSleep'] = dataset['CryoSleep'].apply(\n",
    "        lambda x: np.nan if x!=x else (1 if x else 0))\n",
    "\n",
    "# # # \"Cabin\": new features \"Cabin_Deck\", \"Cabin_num\" and \"Cabin_isPort\" # # #\n",
    "\n",
    "# Generate list of unique values:\n",
    "cabin = list(train_df['Cabin'].loc[~train_df['Cabin'].isna()].values)+\\\n",
    "        list(test_df['Cabin'].loc[~test_df['Cabin'].isna()].values)\n",
    "# Separate \"Cabin\" into three parts:\n",
    "cabin_X = ['Cabin_Deck','Cabin_num','Cabin_Side']\n",
    "for i,cabin in enumerate(cabin_X):\n",
    "    train_df_SF[cabin] = train_df['Cabin'].apply(\n",
    "        lambda x: np.nan if x!=x else (\n",
    "            x.split('/')[i]))\n",
    "    test_df_SF[cabin] = test_df['Cabin'].apply(\n",
    "        lambda x: np.nan if x!=x else (\n",
    "            x.split('/')[i]))\n",
    "# Change 'Cabin_Side' to 'Cabin_isPort' and make it boolean/numeric:\n",
    "train_df_SF['Cabin_isPort'] = train_df_SF['Cabin_Side'].apply(\n",
    "    lambda x: np.nan if x!=x else (1 if x=='P' else 0))\n",
    "test_df_SF['Cabin_isPort'] = test_df_SF['Cabin_Side'].apply(\n",
    "    lambda x: np.nan if x!=x else (1 if x=='P' else 0))\n",
    "# Drop unnecesary features:\n",
    "for feature in ['Cabin','Cabin_Side']:\n",
    "    train_df_SF = train_df_SF.drop(feature,axis=1)\n",
    "    test_df_SF = test_df_SF.drop(feature,axis=1)\n",
    "\n",
    "# # # \"Destination\" redefinition # # #\n",
    "\n",
    "train_df_SF[\"Destination\"] = train_df[\"Destination\"].apply(\n",
    "    lambda x: np.nan if x!=x else (\n",
    "    \"Cancri\" if x==\"55 Cancri e\" else (\n",
    "        \"PSO\" if x==\"PSO J318.5-22\" else \"Trappist\"))\n",
    ")\n",
    "test_df_SF[\"Destination\"] = test_df[\"Destination\"].apply(\n",
    "    lambda x: np.nan if x!=x else (\n",
    "    \"Cancri\" if x==\"55 Cancri e\" else (\n",
    "        \"PSO\" if x==\"PSO J318.5-22\" else \"Trappist\"))\n",
    ")\n",
    "\n",
    "# # # Expense-features redefinition # # #\n",
    "\n",
    "for dataset in [train_df_SF, test_df_SF]:\n",
    "    dataset.rename(columns={\n",
    "        'RoomService': 'ExpRS',\n",
    "        'FoodCourt': 'ExpFC',\n",
    "        'ShoppingMall': 'ExpSM',\n",
    "        'Spa': 'ExpSpa',\n",
    "        'VRDeck': 'ExpVR'\n",
    "        }, inplace=True)\n",
    "\n",
    "# # # \"Name\" feature: new features \"Name_Last\" and \"Ocurrence_LastName\" # # #\n",
    "\n",
    "# Training dataset:\n",
    "train_df_SF['Name_Last'] = train_df['Name'].apply(\n",
    "    lambda x: np.nan if x!=x else (\n",
    "        x.split(' ')[-1]))\n",
    "# Testing dataset:\n",
    "test_df_SF['Name_Last'] = test_df['Name'].apply(\n",
    "    lambda x: np.nan if x!=x else (\n",
    "        x.split(' ')[-1]))\n",
    "# Identify ocurrences for every unique value in Name_Last:\n",
    "ocurrences = pd.concat([train_df_SF['Name_Last'], test_df_SF['Name_Last']]).value_counts().to_dict()\n",
    "for dataset in [train_df_SF,test_df_SF]:\n",
    "    dataset['Ocurrence_LastName'] = dataset['Name_Last'].apply(\n",
    "        lambda x: np.nan if x!=x else ocurrences[x])\n",
    "# Drop unnecessary feature:\n",
    "train_df_SF = train_df_SF.drop('Name',axis=1)\n",
    "test_df_SF = test_df_SF.drop('Name',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e268a000-cb75-406d-abb3-43ee80f7d3cb",
   "metadata": {},
   "source": [
    "Below, I summarize all features after the basic engineering process:\n",
    "\n",
    "| Feature | Definition |\n",
    "| :---: | :--- |\n",
    "| **IDgroup** | Indicates the group with which the passenger is travelling with. People in a group are often family members, but not always. |\n",
    "| **GroupMembers** | Number of passengers sharing the same **IDgroup** (including self). |\n",
    "| **Name_Last** | Last name of the passenger. |\n",
    "| **Ocurrence_LastName** | Number of passengers sharing the same last name (including self). |\n",
    "| **HomePlanet** | The planet the passenger departed from, typically their planet of permanent residence. |\n",
    "| **CryoSleep** | Indicates whether the passenger elected to be put into suspended animation for the duration of the voyage. Passengers in cryosleep are confined to their cabins. |\n",
    "| **Destination** | The planet the passenger will be debarking to. |\n",
    "| **Age** | The age of the passenger. |\n",
    "| **VIP** | Whether the passenger has paid for special VIP service during the voyage. |\n",
    "| **Cabin_Deck** | Designation of the Deck in which the passenger's cabin is located |\n",
    "| **Cabin_num** | Passenger's cabin number |\n",
    "| **Cabin_isPort** | Side of the starship in which the passenger's cabin is located: a value 1 means Port, 0 means Starboard. |\n",
    "| **ExpRS** | Amount the passenger has billed at the Room Service luxury amenity |\n",
    "| **ExpFC** | Amount the passenger has billed at the Food Court luxury amenity |\n",
    "| **ExpSM** | Amount the passenger has billed at the Shopping Mall luxury amenity |\n",
    "| **ExpSpa** | Amount the passenger has billed at the Spa luxury amenity |\n",
    "| **ExpVR** | Amount the passenger has billed at the VRDeck luxury amenity |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021e362d-214f-4292-b57c-4e460ec140ea",
   "metadata": {},
   "source": [
    "<a id=\"Manual_data_correction\"></a>\n",
    "# <span style=\"color:teal;font-weight:bold;\">Manual data correction</span>\n",
    "\n",
    "Xxxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a0cdf6-fb6c-4d90-888f-5b65b9377796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c252420f-137c-4e45-b342-33f165b04a29",
   "metadata": {},
   "source": [
    "<a id=\"Manual_data_correction_Feature_X\"></a>\n",
    "## <span style=\"color:teal;font-weight:bold;\">Feature X</span>\n",
    "\n",
    "Xxxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822bf884-5bcd-4f14-882f-952685010861",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0d83909-5edc-4816-afee-991818080644",
   "metadata": {},
   "source": [
    "<a id=\"ML_data_imputation\"></a>\n",
    "# <span style=\"color:teal;font-weight:bold;\">ML data imputation</span>\n",
    "\n",
    "Xxxx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9dadd5-c6dd-4d35-a1d5-e678b6a081a5",
   "metadata": {},
   "source": [
    "<a id=\"Feature_engineering\"></a>\n",
    "# <span style=\"color:teal;font-weight:bold;\">Feature engineering</span>\n",
    "\n",
    "Xxxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9d04df-56fe-4e94-8adb-837032c6e5d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9cd146d0-2a19-4b1a-8b5b-d4f58b520ba7",
   "metadata": {},
   "source": [
    "<a id=\"Submission_results\"></a>\n",
    "# <span style=\"color:teal;font-weight:bold;\">Submission results</span>\n",
    "\n",
    "Xxxx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acc735a-f6f7-4ca2-9b52-fb61bf34b424",
   "metadata": {},
   "source": [
    "<a id=\"Conclusions\"></a>\n",
    "# <span style=\"color:teal;font-weight:bold;\">Conclusions</span>\n",
    "\n",
    "Xxxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf21a66a-bcbe-45b1-b104-78336f3b31ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
